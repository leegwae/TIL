# Character Encoding

- 비트란 무엇인가? **비트(bit)**는 컴퓨터에서 데이터를 나타내는 최소 단위이다. 0과 1을 나타낼 수 있다.
- 바이트란 무엇인가? **바이트(byte)**는 컴퓨터에서 데이터를 처리하는 최소 단위이다. 8비트의 모임을 1바이트라고 한다.
- 인코딩이란 무엇인가? **인코딩(encoding; 부호화)**는 일련의 규칙에 따라 데이터를 다른 형태로 변환하는 과정이다. 특히, 문자나 기호를 컴퓨터가 처리할 수 있는 비트로 나타내는 과정을 **문자 인코딩(Character Encoding)**이라고 한다.
- 문자 인코딩에는 어떤 종류가 있는가? 문자 인코딩에는 ASCII, UTF-8 등이 있다.
- 디코딩이란 무엇인가? **디코딩(decoding; 복호화)**는 일련의 규칙에 따라 데이터를 원래의 형태로 복원하는 과정이다.
- ASCII란 무엇인가? **ASCII(American Standard Code for Information Interchange; 아스키)**는 7비트를 사용하여 128개의 문자(영문 알파벳 대소문자, 숫자, 특수 문자, 공백 문자)를 인코딩한다. (1비트는 통신 과정에서 오류 검출을 위해 사용하였다고 한다.)
- ANSI란 무엇인가? **ANSI(American National Standards Institute)**는 확장된 ASCII로, 8비트를 사용하여 256개의 문자를 인코딩한다. 마지막 1비트는 CodePage를 의미하는데, 이 비트마다 다른 언어 문자의 표를 의미한다.
- EUC-KR은 무엇인가? **EUC-KR(Extended Unix Code-Korea)**는 ASNI를 한국에서 확장한 것으로 ASCII 문자를 1바이트로, 한글 문자 하나를 2바이트로 표현한다. 초성, 중성, 종성을 조합하는 것이 아니라 완성된 글자로 표현되기 때문에 표현하지 못하는 문자가 있다.
- CP949는 무엇인가? **CP949**는 마이크로소프트가 Windows 운영체제에서 한글을 지원하기 위해 만든 EUC-KR의 확장 버전으로 더 많은 문자를 표현할 수 있으며, Windows 운영체제에서 사용한다.
- ASCII의 문제점은 무엇인가? ASCII는 1바이트로는 세계의 모든 기호나 문자를 처리할 수 없었다. 예를 들어, ASCII로 한글을 인코딩하면 2바이트 이상을 사용해야했기 때문에 글자가 깨지는 등의 문제가 발생했다.
- 유니코드란 무엇인가? **유니코드(Unicode) 방식**은 전 세계의 모든 기호나 문자를 일관되게 표현하고 처리하기 위해 설계된 산업 표준 인코딩 방식이다. 유니코드 자체는 인코딩 방식이 아니며, 다만 문자와 기호를 2바이트로 매핑한 것이다. 유니코드를 인코딩하는 방식에는 대표적으로 가변 길이 방식의 UTF-8과 UTF-16이 있다.
- 고정 길이 유니코드 방식의 문제점은 무엇인가? 고정 길이 유니코드 방식은 2바이트를 사용하기 때문에 ASCII 방식에서 2~4바이트에 한 개의 문자를 표현하며 나타났던 문제들이 나타나지 않았다. 그러나 1바이트로 표현 가능했던 문자도 2바이트를 사용해야 하는 메모리 낭비 문제가 발생했다.
- UTF-8은 무엇인가? **UTF-8(8-bit Unicode Transformation Format)**은 하나의 문자를 1바이트에서 4바이트로 나타내는 가변 길이 문자 인코딩 방식이다. 영문자는 1바이트, 한글은 3바이트를 사용하여 나타낸다. 아스키 코드와 호환가능하다. Mac과 Linux 운영체제에서 사용한다.
- UTF-16은 무엇인가? **UTF-16(16-bit Unicode Transformation Format)**은 하나의 문자를 2바이트에서 4바이트로 나타내는 가변 길이 문자 인코딩 방식이다. (BMP(BMP, Basic multilingual plane)에 속하는 문자를 2바이트로, 그 외의 문자는 4바이트로 나타낸다.) 한글과 영문자 모두 2바이트로 처리할 수 있다. 아스키 코드와는 호환되지 않는다.

